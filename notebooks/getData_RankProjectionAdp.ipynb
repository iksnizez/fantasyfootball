{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be771a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run date: 2025-08-26 \n",
      "Week: 0 \n",
      "inseason run: False \n",
      "export files: True\n"
     ]
    }
   ],
   "source": [
    "##### importing custom modules from the projects folder\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Add project root to sys.path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "import modules.scrapers as scrapers\n",
    "import modules.helperModule as hf\n",
    "##### --------------\n",
    "from datetime import date\n",
    "\n",
    "# ====================================\n",
    "#                    PARAMS \n",
    "# ====================================\n",
    "league = 'nfl'\n",
    "export = True # export to csv files\n",
    "today = date.today()\n",
    "season = 2025\n",
    "week = 0\n",
    "inseason = False  # False for running proj, and rank scrapes in the offseason\n",
    "#week = int(input(\"What week is it >>>>>> ? \"))\n",
    "print('Run date:',today, \"\\nWeek:\", week, '\\ninseason run:', inseason, '\\nexport files:', export)\n",
    "# ====================================\n",
    "\n",
    "scraper = scrapers.scrapers(\n",
    "    season = season,\n",
    "    week = week,\n",
    "    today = today\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393dfb8",
   "metadata": {},
   "source": [
    "# SCRAPE DATA\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4dd0e",
   "metadata": {},
   "source": [
    "### INSEASON - Actual game scores and Game betting lines\n",
    "##### run after the last game of the week before TNF game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.cbs_game_scores(inseason = inseason, export = export)\n",
    "scraper.bp_lines(export = export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2663eb",
   "metadata": {},
   "source": [
    "### INSEASON or OFFSEASON - Projections and Rankings\n",
    "##### offseason - run at any time in the offseason once sites put them up\n",
    "##### inseason - run anytime Tues-Thurs before TNF to get the proj or ranks before cames start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7028f15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 60)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in- and off-season\n",
    "scraper.cbs_projections(inseason = inseason, export = export)\n",
    "scraper.espn_projections(inseason = inseason, export = export)\n",
    "scraper.nfl_projections(inseason = inseason, export = export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c14652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:1547: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_espn_ranking = pd.concat([df_espn_ranking, temp_df], axis = 0, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(384, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in- and off-season\n",
    "scraper.ffp_ecr_rankings(inseason = inseason, export = export)\n",
    "scraper.espn_rankings(inseason = inseason, export = export)\n",
    "scraper.nfl_rankings(inseason = inseason, export = export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dab6a5",
   "metadata": {},
   "source": [
    "###  OFFSEASON - ADPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16577e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper.cbs_adp(export = export)\n",
    "scraper.ffp_adp(export = export)\n",
    "scraper.espn_adp(export = export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502c7f8",
   "metadata": {},
   "source": [
    "### OFFSEASON - player full season yard and td props "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bffe10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rushing_yds 1 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 2 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 3 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 4 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 5 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 6 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 7 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 8 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 9 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 10 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 11 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 12 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 1 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 2 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 3 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 4 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 5 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 6 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 7 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 8 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 9 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 10 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 11 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 12 <Response [200]>\n",
      "soup ruined\n",
      "total_receiving_yds 1 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 2 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 3 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 4 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 5 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 6 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 7 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 8 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 9 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 10 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 11 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 12 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 13 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 14 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 15 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 16 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 17 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 18 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 19 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 20 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 21 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 22 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 1 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 2 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 3 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 4 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 5 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 6 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 7 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 8 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 9 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 10 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 11 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 12 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 13 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 14 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 15 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 16 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 17 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 18 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 1 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 2 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 3 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 4 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 5 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 6 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 7 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 1 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 2 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 3 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 4 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 5 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 6 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 7 <Response [200]>\n",
      "made soup\n"
     ]
    }
   ],
   "source": [
    "scraper.bp_season_player_total_props()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025001d",
   "metadata": {},
   "source": [
    "# PROCESS SCRAPED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e95e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query successful\n",
      "query successful\n",
      "query successful\n",
      "query successful\n",
      "query successful\n",
      "query successful\n"
     ]
    }
   ],
   "source": [
    "# hit db to standardize player, team, outlet, etc... ids \n",
    "scraper.generate_id_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8764072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2776: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_load_proj = pd.concat([df_load_proj, temp])\n",
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2763: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_missing_players_proj = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing players..\n",
      "query successful\n",
      "query successful\n",
      "updates completed...\n"
     ]
    }
   ],
   "source": [
    "scraper.process_projections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be0e48ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing players\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2641: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_load_rank = pd.concat([df_load_rank, temp])\n"
     ]
    }
   ],
   "source": [
    "scraper.process_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a51f743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbs_adp_2025-00_2025-08-26.csv\n",
      "espn_adp_2025-00_2025-08-26.csv\n",
      "fp_adp_2025-00_2025-08-26.csv\n",
      "raw\n",
      "no missing players\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2908: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_load_adp = pd.concat([df_load_adp, temp])\n"
     ]
    }
   ],
   "source": [
    "scraper.process_adps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b902098",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.process_game_lines(bettingTableName = 'betting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "910d6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run when season total props are scraped.\n",
    "scraper.process_season_player_total_props()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc50fc",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a73960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJ: (1544, 56) \n",
      "RANK: (2953, 10) \n",
      "ADP: (2055, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'PROJ:', scraper.processed_dfs['projections'].shape,\n",
    "    '\\nRANK:', scraper.processed_dfs['rankings'].shape,\n",
    "    '\\nADP:', scraper.processed_dfs['adps'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "558f8fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2055, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================\n",
    "# remove nan player ids if the loads fail below\n",
    "# COME BACK TO HERE IF THE 3 expor_Database() calls below fail for nans \n",
    "# =============================================\n",
    "table = 'adps'\n",
    "\n",
    "scraper.processed_dfs[table] = scraper.processed_dfs[table][\n",
    "    scraper.processed_dfs[table]['playerId'].notna()\n",
    "]\n",
    "scraper.processed_dfs[table].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27277712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully added data to projection\n"
     ]
    }
   ],
   "source": [
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['projections'],\n",
    "    database_table='projection', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a50453",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['rankings'],\n",
    "    database_table='ranking', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['adps'],\n",
    "    database_table='adp', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed70879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['lines'], \n",
    "    database_table='betting', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43335fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['seasonprops'], \n",
    "    database_table='odds_season_totals', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8a69a",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43037f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load sleeper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasyfootball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
