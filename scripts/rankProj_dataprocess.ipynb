{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3ea065-fdc4-46cd-bdcd-d14d5524ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What week is it >>>>>> ?  1\n"
     ]
    }
   ],
   "source": [
    "import requests, time, re, os, json\n",
    "import pymysql, pyodbc\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import date\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#importing credentials\n",
    "with open('../../../Notes-General/config.txt', 'r') as f:\n",
    "    creds = f.read()\n",
    "creds = json.loads(creds)\n",
    "league = 'nfl'\n",
    "\n",
    "# import credentials\n",
    "dbUser = creds['mysqlSurface']['users'][1]\n",
    "dbPw = creds['mysqlSurface']['creds']['jb']\n",
    "dbHost = creds['mysqlSurface']['dbNFL']['host']\n",
    "dbName = creds['mysqlSurface']['dbNFL']['database']\n",
    "dbConnectionString = creds['pymysql'][league]\n",
    "\n",
    "today = date.today()\n",
    "season = 2024\n",
    "week = int(input(\"What week is it >>>>>> ? \"))\n",
    "if week < 10:\n",
    "    strWeek = \"0\" + str(week)\n",
    "else:\n",
    "    strWeek = week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc8d1a8-4e5c-45e4-bd29-0e2c78e90b03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "teammap = {'ATL': 'ATL',\n",
    " 'BUF': 'BUF',\n",
    " 'CHI': 'CHI',\n",
    " 'CIN': 'CIN',\n",
    " 'CLE': 'CLE',\n",
    " 'DAL': 'DAL',\n",
    " 'DEN': 'DEN',\n",
    " 'DET': 'DET',\n",
    " 'GB': 'GB',\n",
    " 'TEN': 'TEN',\n",
    " 'IND': 'IND',\n",
    " 'KC': 'KC',\n",
    " 'LV': 'LV',\n",
    " 'LAR': 'LA',\n",
    " 'MIA': 'MIA',\n",
    " 'MIN': 'MIN',\n",
    " 'NE': 'NE',\n",
    " 'NO': 'NO',\n",
    " 'NYG': 'NYG',\n",
    " 'NYJ': 'NYJ',\n",
    " 'PHI': 'PHI',\n",
    " 'ARI': 'ARI',\n",
    " 'PIT': 'PIT',\n",
    " 'LAC': 'LAC',\n",
    " 'SF': 'SF',\n",
    " 'SEA': 'SEA',\n",
    " 'TB': 'TB',\n",
    " 'WSH': 'WAS',\n",
    " 'CAR': 'CAR',\n",
    " 'JAX': 'JAX',\n",
    " 'BAL': 'BAL',\n",
    " 'HOU': 'HOU',\n",
    " 'FA': 'FA',\n",
    " 'STL': 'SL',\n",
    " 'SD': 'SD',\n",
    " 'OAK': 'OAK'}\n",
    "teammapid = {'ATL': '3800',\n",
    " 'BUF': '0610',\n",
    " 'CHI': '0810',\n",
    " 'CIN': '0920',\n",
    " 'CLE': '1050',\n",
    " 'DAL': '1200',\n",
    " 'DEN': '1400',\n",
    " 'DET': '1540',\n",
    " 'GB': '1800',\n",
    " 'TEN': '2100',\n",
    " 'IND': '2200',\n",
    " 'KC': '2310',\n",
    " 'LV': '2520',\n",
    " 'LAR': '2510',\n",
    " 'MIA': '2700',\n",
    " 'MIN': '3000',\n",
    " 'NE': '3200',\n",
    " 'NO': '3300',\n",
    " 'NYG': '3410',\n",
    " 'NYJ': '3430',\n",
    " 'PHI': '3700',\n",
    " 'ARI': '3800',\n",
    " 'PIT': '3900',\n",
    " 'LAC': '4400',\n",
    " 'SF': '4500',\n",
    " 'SEA': '4600',\n",
    " 'TB': '4900',\n",
    " 'WSH': '5110',\n",
    " 'CAR': '0750',\n",
    " 'JAX': '2250',\n",
    " 'BAL': '0325',\n",
    " 'HOU': '2120',\n",
    " 'FA': '0',\n",
    " 'STL': '0',\n",
    " 'SD': '0',\n",
    " 'OAK': '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299adc92-cb96-4ea3-9a18-df83a5015328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lookup dictionaries that will be used across multiple database inserts\n",
    "try:\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # getting outlet db ids to convert the scraped names/ids\n",
    "    outletLookup = pd.read_sql(\"SELECT outletId, outletName  FROM outlet;\", conn)\n",
    "    outletLookup = pd.Series(outletLookup.outletId.values, index=outletLookup.outletName).to_dict()\n",
    "    \n",
    "    # getting team db ids to convert datasource names to the ids\n",
    "    #teamLookup = pd.read_sql(\"SELECT teamId, name  FROM team;\", conn)\n",
    "    teamLookup = pd.read_sql(\"SELECT teamId, nflfastrName  FROM team;\", conn)\n",
    "    teams = pd.read_sql(\"SELECT *  FROM team;\", conn)\n",
    "    teamLookup = pd.Series(teamLookup.teamId.values, index=teamLookup.nflfastrName).to_dict()\n",
    "    \n",
    "    \n",
    "    # getting expert db ids to convert the scraped names/ids\n",
    "    expertLookup = pd.read_sql(\"SELECT analystId, analystName  FROM analyst;\", conn)\n",
    "    expertLookup = pd.Series(expertLookup.analystId.values, index=expertLookup.analystName).to_dict()\n",
    "\n",
    "    # getting pos db ids for espn\n",
    "    posLookup = pd.read_sql(\"SELECT posId, pos  FROM pos;\", conn)\n",
    "    posLookup = pd.Series(posLookup.posId.values, index=posLookup.pos).to_dict()\n",
    "\n",
    "    # create name table back up\n",
    "    names = pd.read_sql(con=conn, sql=\"SELECT * FROM player\")\n",
    "    names.to_csv(\"../data/names_backup.csv\", index=False)\n",
    "\n",
    "    dbPlayers = pd.read_sql(\"SELECT joinName, team, position FROM players WHERE season = 2023;\", conn)\n",
    "    dbPlayers = pd.read_sql(\"SELECT * FROM players;\", conn)\n",
    "\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648d628-f74d-4252-be5e-2674286412fd",
   "metadata": {},
   "source": [
    "# ADDING NEW PLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790929b4-9890-4ebc-9cfa-cf3cad716077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e10afd-9589-4697-b2d9-05c6ff94ec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eb97ff9-518f-45f7-aaed-26babf5b96d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LOAD RANKINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee0def-7878-4876-a8d1-b4e1bc3e5e67",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #main df to hold all data\n",
    "    df_load_rank = pd.DataFrame(columns = [\n",
    "        'outlet', 'date', 'season', 'week', 'group', 'expert', 'rank', 'high', 'low','playerId'\n",
    "    ])\n",
    "\n",
    "    # df to hold players that are not in the database for a source yet\n",
    "    df_missing_players_rank = pd.DataFrame(columns=['date', 'outlet', 'group', 'playerId', 'sourceId', 'name'])\n",
    "\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    with engine.connect() as conn:\n",
    "\n",
    "        # combining all outlets rankings to a single dataframe and converting names to the database Ids\n",
    "        directory = r'../data/ranking/weekly'\n",
    "        #looping through every rank file to aggregate into single df\n",
    "        for filename in os.listdir(directory):\n",
    "            f = os.path.join(directory,filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(f):\n",
    "                temp = pd.read_csv(f, parse_dates=['date'], infer_datetime_format=True,\n",
    "                                   ###################################################################\n",
    "                                   names=['outlet','date', 'season', 'week', 'group', 'expert', 'rank', \n",
    "                                          'name', 'sourceId', 'team', 'pos', 'high', 'low', 'playerId'],\n",
    "                          skiprows=1)\n",
    "                            ##########################################################################\n",
    "\n",
    "                # updtaing outlet specific playerIds to database IDs\n",
    "                if 'cbs_' in f:\n",
    "                    lookup = pd.read_sql(\"SELECT playerId, cbsId FROM player WHERE cbsId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup['playerId'].values, index=lookup.cbsId).to_dict()\n",
    "\n",
    "                elif 'espn_' in f:\n",
    "                    lookup = pd.read_sql(\"SELECT playerId, espnId FROM player WHERE espnId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.playerId.values, index=lookup.espnId).to_dict()\n",
    "\n",
    "                elif ('fp_' in f) or ('fpEcr_' in f):\n",
    "                    lookup = pd.read_sql(\"SELECT playerId, fpId FROM player WHERE fpId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.playerId.values, index=lookup.fpId).to_dict()\n",
    "\n",
    "                elif 'nfl_' in f:\n",
    "                    lookup = pd.read_sql(\"SELECT playerId, nflId FROM player WHERE nflId IS NOT NULL;\", conn)\n",
    "                    lookup['nflId'] = pd.to_numeric(lookup['nflId']) \n",
    "                    lookup = pd.Series(lookup.playerId.values, index=lookup.nflId).to_dict()\n",
    "\n",
    "                # using the lookup to make the change from outletId to dbId\n",
    "                temp['playerId'] = temp['sourceId'].map(lookup)\n",
    "\n",
    "                ####################################\n",
    "                # creating a df to hold that date for players who are not in the player table for the source\n",
    "                if temp[pd.isnull(temp['playerId'])].shape[0] > 0:\n",
    "                    df_missing_players_rank = pd.concat(\n",
    "                                                    [df_missing_players_rank, \n",
    "                                                    temp.loc[\n",
    "                                                             pd.isnull(temp['playerId']), \n",
    "                                                             ['date', 'outlet', 'group', \n",
    "                                                              'playerId', 'sourceId', 'name']\n",
    "                                                        ]\n",
    "                                                    ]\n",
    "                                            )\n",
    "                    df_missing_players_rank['joinName'] = df_missing_players_rank['name'].str.lower()\n",
    "                    df_missing_players_rank['joinName'] = df_missing_players_rank['joinName'].str.replace(\".\", \"\")\n",
    "                    df_missing_players_rank['joinName'] = df_missing_players_rank['joinName'].str.replace(\"''\", \"\")\n",
    "                    df_missing_players_rank['joinName'] = df_missing_players_rank['joinName'].str.replace(\"`\", \"\")\n",
    "                    df_missing_players_rank['joinName'] = df_missing_players_rank['joinName'].str.replace(\"\", \"\")\n",
    "                    \n",
    "                    # grab the player data from nflfastR\n",
    "                    dbPlayers = pd.read_sql(\"SELECT joinName, team, position FROM players ;\", conn)\n",
    "                    \n",
    "                    # processing data\n",
    "                    dbPlayers['position'] = dbPlayers['position'].replace(posLookup)\n",
    "                    dbPlayers['team'] = dbPlayers['team'].replace(teamLookup)\n",
    "\n",
    "                    \n",
    "                    # adding position and team id to missing data\n",
    "                    df_missing_players_rank = df_missing_players_rank.join(dbPlayers, on='joinName', how='left')\n",
    "                    \n",
    "                \n",
    "                ####################################\n",
    "\n",
    "                # updating outlet name to db outlet id \n",
    "                temp['outlet'] = temp['outlet'].replace(outletLookup)\n",
    "\n",
    "                #updating expert name to db expert id\n",
    "                temp['expert'] = temp['expert'].replace(expertLookup)\n",
    "\n",
    "                temp = temp[['outlet', 'date', 'season', 'week', 'group', 'expert', 'rank', 'high', 'low', 'playerId']]\n",
    "                # adding outlet dataframe to the upload dataframe\n",
    "                df_load_rank = pd.concat([df_load_rank, temp])\n",
    "\n",
    "                \n",
    "    df_load_rank = df_load_rank.replace(np.nan, None)\n",
    "    # removing unranked players and rankings that have been loaded already\n",
    "    df_load_rank = df_load_rank.loc[pd.notnull(df_load_rank['rank'])]\n",
    "    df_load_rank = df_load_rank.loc[df_load_rank['date'] >= pd.to_datetime(today)]\n",
    "\n",
    "\n",
    "\n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ade86b-a414-4ce4-8386-c95a5e73b418",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if df_missing_players_rank.shape[0] > 0:\n",
    "    df_missing_players_rank.to_csv('../data/missingPlayersRank.csv')\n",
    "df_missing_players_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df3140-9e9b-4ace-90a5-0050cd790838",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    with engine.connect() as conn:\n",
    "        \n",
    "        # insert using SQLalchemy\n",
    "        data = df_load_rank.replace(np.nan, None).values.tolist()\n",
    "        rankMeta = sal.MetaData(engine)\n",
    "        rankTable = sal.Table('ranking', rankMeta, autoload=True)\n",
    "        conn.execute(sal.insert(rankTable).values(data))\n",
    "    \n",
    "    ''' old mysql.connector connection\n",
    "        query_insert = \"\"\"\n",
    "            INSERT INTO ranking \n",
    "                (outletId, date, season, week, rankGroup, analystId, ranking, high, low, playerId)\n",
    "            VALUES \n",
    "                (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "\n",
    "        cursor.executemany(query_insert, df_load_rank.values.tolist())\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        '''\n",
    "    print(\"success\")\n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9156230-f6de-4f68-8099-016e8761a67a",
   "metadata": {},
   "source": [
    "#### INPUT TO CONTROL DB ACTIONS - USED TO MANUALLY ADD PLAYERS MISSING FROM DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a248c0c-7f09-4e08-9999-a8fee0e0d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 'update'\n",
    "source = 'cbs'\n",
    "\n",
    "db_action = {\n",
    "            'update':{\n",
    "                        \"espn\": \"\"\"UPDATE player SET espnId = %s,espnName = %s WHERE playerId = %s\"\"\",\n",
    "                         \"cbs\": \"\"\"UPDATE player SET cbsId = %s,cbsName = %s WHERE playerId = %s\"\"\",\n",
    "                         \"fp\": \"\"\"UPDATE player SET fpId = %s,fpName = %s WHERE playerId = %s\"\"\",\n",
    "                         \"nfl\": \"\"\"UPDATE player SET nflId = %s,nflName = %s WHERE playerId = %s\"\"\"\n",
    "                },\n",
    "             'add':{\n",
    "                         \"espn\": \"\"\"INSERT INTO player (posId,teamId,espnId,espnName,name) VALUES (%s,%s,%s,%s,%s)\"\"\",\n",
    "                         \"cbs\": \"\"\"INSERT INTO player (posId,teamId,cbsId,cbsName,name) VALUES (%s,%s,%s,%s,%s)\"\"\",\n",
    "                         \"fp\": \"\"\"INSERT INTO player (posId,teamId,fpId,fpName,name) VALUES (%s,%s,%s,%s,%s)\"\"\",\n",
    "                         \"nfl\": \"\"\"INSERT INTO player (posId,teamId,nflId,nflName,name) VALUES (%s,%s,%s,%s,%s)\"\"\"\n",
    "             },\n",
    "            'delete':{\n",
    "                \n",
    "            }\n",
    "}\n",
    "\n",
    "db_action[action][source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e65d1b-ca97-4e35-b646-7b47b9cf321e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#####\n",
    "## THIS CAN BE USED TO UPDATE THE DB FOR MISSING PLAYERS\n",
    "#####\n",
    "df_missing = pd.read_excel(r'../data/adds.xlsx', sheet_name=action)\n",
    "\n",
    "try:\n",
    "    #engine = create_engine(dbConnectionString)\n",
    "    #conn = engine.connect()\n",
    "    conn = mysql.connector.connect(user=dbUser, password=dbPw,\n",
    "                              host=dbHost,database=dbName)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.executemany(db_action[action][source], df_missing.values.tolist())\n",
    "        \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"success\")\n",
    "    \n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca540040-7041-4779-b718-a5bee7cba22e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LOAD PROJECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8c991-5479-4db6-bd94-3d3200706710",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:  \n",
    "    projection_columns_dbLoad = [\"playerId\", \"date\", \"season\", \"week\", \"outlet\",'GamesPlayed',\n",
    "     'PassAttempts','PassCompletions','PassingYards', 'PassingYardsPerGame', 'TouchdownsPasses', \n",
    "     'InterceptionsThrown', 'PasserRating','RushingAttempts','RushingYards', 'AverageYardsPerRush', 'RushingTouchdowns',\n",
    "     'Targets', 'Receptions', 'ReceivingYards', 'YardsPerGame', 'AverageYardsPerReception','ReceivingTouchdowns',\n",
    "     'FumblesLost','FieldGoalsMade','FieldGoalAttempts','LongestFieldGoal','FieldGoals119Yards','FieldGoals119YardAttempts',\n",
    "     'FieldGoals2029Yards','FieldGoals2029YardAttempts','FieldGoals3039Yards','FieldGoals3039YardAttempts',\n",
    "     'FieldGoals4049Yards','FieldGoals4049YardAttempts','FieldGoals50Yards','FieldGoals50YardsAttempts',\n",
    "     'ExtraPointsMade','ExtraPointsAttempted','Interceptions','Safeties','Sacks','Tackles','DefensiveFumblesRecovered',\n",
    "     'ForcedFumbles','DefensiveTouchdowns', 'ReturnTouchdowns','PointsAllowed','PointsAllowedPerGame','NetPassingYardsAllowed',\n",
    "     'RushingYardsAllowed','TotalYardsAllowed', 'YardsAgainstPerGame', 'twoPt', 'FantasyPoints','FantasyPointsPerGame']\n",
    "\n",
    "    projcols = ['outlet', 'date', 'season', 'week', 'sourceId', 'name', 'shortName', 'pos', 'team', 'GamesPlayed', \n",
    "                'PassAttempts', 'PassCompletions', 'PassingYards', 'PassingYardsPerGame', 'TouchdownsPasses', \n",
    "                'InterceptionsThrown', 'PasserRating', 'RushingAttempts', 'RushingYards', 'AverageYardsPerRush', \n",
    "                'RushingTouchdowns', 'Targets', 'Receptions', 'ReceivingYards', 'YardsPerGame', 'AverageYardsPerReception', \n",
    "                'ReceivingTouchdowns', 'FumblesLost', 'FieldGoalsMade', 'FieldGoalAttempts', 'LongestFieldGoal', \n",
    "                'FieldGoals119Yards', 'FieldGoals119YardAttempts', 'FieldGoals2029Yards', 'FieldGoals2029YardAttempts', \n",
    "                'FieldGoals3039Yards', 'FieldGoals3039YardAttempts', 'FieldGoals4049Yards', 'FieldGoals4049YardAttempts', \n",
    "                'FieldGoals50Yards', 'FieldGoals50YardsAttempts', 'ExtraPointsMade', 'ExtraPointsAttempted', 'Interceptions', \n",
    "                'Safeties', 'Sacks', 'Tackles', 'DefensiveFumblesRecovered', 'ForcedFumbles', 'DefensiveTouchdowns', \n",
    "                'ReturnTouchdowns', 'PointsAllowed', 'PointsAllowedPerGame', 'NetPassingYardsAllowed',  'RushingYardsAllowed',\n",
    "                'TotalYardsAllowed', 'YardsAgainstPerGame', 'twoPt', 'FantasyPoints', 'FantasyPointsPerGame']\n",
    "\n",
    "    #main df to hold all data\n",
    "    df_load_proj = pd.DataFrame(columns = projection_columns_dbLoad)\n",
    "    \n",
    "    # df to hold players that are not in the database for a source yet\n",
    "    df_missing_players_proj = pd.DataFrame(columns=['date', 'outlet', 'playerId', 'sourceId', 'name'])\n",
    "\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    with engine.connect() as conn:\n",
    "    \n",
    "        directory = r'../data/projection/weekly'\n",
    "        #looping through every ADP file to aggregate into single df\n",
    "        for filename in os.listdir(directory):\n",
    "            f = os.path.join(directory,filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(f):\n",
    "                temp = pd.read_csv(f, parse_dates=['date'], \n",
    "                                   names=projcols,\n",
    "                          skiprows=1)\n",
    "\n",
    "                # creating dicts to convert outlet name/id to db id\n",
    "                if 'cbs' in f:\n",
    "\n",
    "                    # converting full team name to db table 'TEAM'.name\n",
    "                    lookup = pd.read_sql(\"SELECT cbsId, name FROM player WHERE cbsId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.cbsId.values, index=lookup.name).to_dict()\n",
    "\n",
    "                    # updating the cbs source data full team name to the abbreviated db name\n",
    "                    temp['team'] = temp['team'].replace(\"JAC\", \"JAX\").replace(\"WAS\",\"WSH\")\n",
    "                    temp.loc[temp['sourceId'].isna(), 'sourceId'] = temp.loc[temp['sourceId'].isna(), 'team'].map(lookup)\n",
    "\n",
    "                    # cbs source data does not have playerId for the defenses\n",
    "                    lookup = pd.read_sql(\"SELECT playerId, cbsId FROM player WHERE cbsId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup['playerId'].values, index=lookup.cbsId).to_dict()\n",
    "\n",
    "                elif 'espn' in f:\n",
    "                    # espn source data does not have playerId for the defenses\n",
    "                     # converting full team name to db table 'TEAM'.name\n",
    "                    lookup = pd.read_sql(\"SELECT espnId, name FROM player WHERE espnId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.espnId.values, index=lookup.name).to_dict()\n",
    "\n",
    "                    # updating the nfl source data full team name to the abbreviated db name\n",
    "                    temp.loc[temp['sourceId'].isna(), 'sourceId'] = temp.loc[temp['sourceId'].isna(), 'team'].map(lookup)\n",
    "\n",
    "                    lookup = pd.read_sql(\"SELECT espnId, playerId FROM player WHERE espnId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.playerId.values, index=lookup.espnId).to_dict()\n",
    "\n",
    "\n",
    "                elif 'nfl' in f:\n",
    "                    # converting full team name to db table 'TEAM'.name\n",
    "                    lookup = pd.read_sql(\"SELECT nflName, name FROM team WHERE nflName IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.name.values, index=lookup.nflName).to_dict()\n",
    "\n",
    "                    # updating the nfl source data full team name to the abbreviated db name\n",
    "                    temp.loc[temp['name'].isna(), 'team'] = temp.loc[temp['name'].isna(), 'team'].map(lookup)\n",
    "\n",
    "                    lookup = pd.read_sql(\"SELECT playerId, nflId FROM player WHERE nflId IS NOT NULL;\", conn)\n",
    "                    lookup = pd.Series(lookup.playerId.values, index=lookup.nflId).to_dict()\n",
    "\n",
    "\n",
    "                # using the lookup to make the change from outletId to dbId\n",
    "                temp['playerId'] = temp['sourceId'].map(lookup)\n",
    "\n",
    "                # creating a df to hold that date for players who are not in the player table for the source\n",
    "                if temp[pd.isnull(temp['playerId'])].shape[0] > 0:\n",
    "                    df_missing_players_proj = pd.concat([df_missing_players_proj, \n",
    "                                                    temp.loc[pd.isnull(temp['playerId']), ['date', 'outlet', 'playerId', 'sourceId', 'name']]])\n",
    "\n",
    "                # updating outlet name to db outlet id \n",
    "                temp['outlet'] = temp['outlet'].replace(outletLookup)\n",
    "\n",
    "\n",
    "                temp = temp[projection_columns_dbLoad].replace(\"-\", None).replace(\"—\", None)\n",
    "\n",
    "                df_load_proj = pd.concat([df_load_proj, temp])\n",
    "\n",
    "    df_load_proj = df_load_proj.replace(np.nan, None)\n",
    "\n",
    "    \n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe57d1-c326-4dc0-8757-ff0b61dc1d23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if df_missing_players_proj.shape[0] > 0:\n",
    "    df_missing_players_proj.to_csv('../data/missingPlayersProj.csv')\n",
    "df_missing_players_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9b68c-45e8-4603-9c3f-dae0e5e35254",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    with engine.connect() as conn:\n",
    "        \n",
    "        # insert using SQLalchemy\n",
    "        data = df_load_proj.replace(np.nan, None).values.tolist()\n",
    "        projMeta = sal.MetaData(engine)\n",
    "        projTable = sal.Table('projection', projMeta, autoload=True)\n",
    "        conn.execute(sal.insert(projTable).values(data))\n",
    "\n",
    "        '''  old connection using mysql.connector\n",
    "        query_insert = \"\"\"\n",
    "            INSERT INTO projection \n",
    "            VALUES \n",
    "                (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                 %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                 %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        cursor.executemany(query_insert, df_load_proj.values.tolist())\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        '''\n",
    "    print(\"success\")\n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86b65c-d91a-4b1c-b695-79d9faa98e8f",
   "metadata": {},
   "source": [
    "# INSERT BETTING LINES - updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd3b4b2-6025-4597-875c-f733a198fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrbrz\\AppData\\Local\\Temp\\ipykernel_7260\\3401799653.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_lines = pd.concat([df_lines, temp], ignore_index=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tran' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(dbConnectionString)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m     23\u001b[0m     tran \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mbegin()\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3264\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \n\u001b[0;32m   3244\u001b[0m \u001b[38;5;124;03mThe :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3261\u001b[0m \n\u001b[0;32m   3262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3288\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3268\u001b[0m \n\u001b[0;32m   3269\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3286\u001b[0m \n\u001b[0;32m   3287\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:452\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:1267\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1267\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:716\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:170\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\impl.py:167\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:393\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:678\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:903\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m--> 903\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:147\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\pool\\base.py:898\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\engine\\create.py:637\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\sqlalchemy\\engine\\default.py:615\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\pymysql\\connections.py:358\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\pymysql\\connections.py:664\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_information()\n\u001b[1;32m--> 664\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_authentication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\pymysql\\connections.py:976\u001b[0m, in \u001b[0;36mConnection._request_authentication\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_plugin_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaching_sha2_password\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 976\u001b[0m     auth_packet \u001b[38;5;241m=\u001b[39m \u001b[43m_auth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaching_sha2_password_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_packet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_plugin_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha256_password\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\pymysql\\_auth.py:266\u001b[0m, in \u001b[0;36mcaching_sha2_password_auth\u001b[1;34m(conn, pkt)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28mprint\u001b[39m(conn\u001b[38;5;241m.\u001b[39mserver_public_key\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 266\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msha2_rsa_encrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msalt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_public_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m pkt \u001b[38;5;241m=\u001b[39m _roundtrip(conn, data)\n",
      "File \u001b[1;32m~\\.virtualenvs\\fantasyfootball-_eDnYwQS\\lib\\site-packages\\pymysql\\_auth.py:143\u001b[0m, in \u001b[0;36msha2_rsa_encrypt\u001b[1;34m(password, salt, public_key)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _have_cryptography:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcryptography\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m package is required for sha256_password or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m caching_sha2_password auth methods\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m     )\n\u001b[0;32m    147\u001b[0m message \u001b[38;5;241m=\u001b[39m _xor_password(password \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, salt)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 'cryptography' package is required for sha256_password or caching_sha2_password auth methods",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mtran\u001b[49m\u001b[38;5;241m.\u001b[39mrollback()\n\u001b[0;32m     39\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ex)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tran' is not defined"
     ]
    }
   ],
   "source": [
    "directory = r'../data/betting'\n",
    "bettingTableName = 'betting'\n",
    "\n",
    "bettingCols = ['date', 'season', 'week', 'overUnder', 'overUnderCost', 'awayTeamId',\n",
    "               'awaySpread', 'awayCost', 'awayMoneyline', 'homeTeamId', 'homeSpread',\n",
    "               'homeCost', 'homeMoneyLine']\n",
    "\n",
    "df_lines = pd.DataFrame(columns=bettingCols)\n",
    "\n",
    "#looping through every betting line file to aggregate into single df\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory,filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        temp = pd.read_csv(f, parse_dates=['date'],  names=bettingCols, skiprows=1)\n",
    "        df_lines = pd.concat([df_lines, temp], ignore_index=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        tran = conn.begin()\n",
    "\n",
    "        lookup = pd.read_sql(\"SELECT bpName, teamId FROM team;\", conn)\n",
    "        lookup = pd.Series(lookup.teamId.values, index=lookup.bpName).to_dict()\n",
    "            \n",
    "        df_lines['awayTeamId'] = df_lines['awayTeamId'].map(lookup)\n",
    "        df_lines['homeTeamId'] = df_lines['homeTeamId'].map(lookup)\n",
    "\n",
    "        df_lines.to_sql(bettingTableName, conn, if_exists='append', index=False)\n",
    "\n",
    "        tran.commit()\n",
    "        conn.close()\n",
    "\n",
    "    print(\"success\")\n",
    "except Exception as ex:\n",
    "    tran.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7fe60-1d16-4a30-b3a8-848bcf7b9f13",
   "metadata": {},
   "source": [
    "# OLDER DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7a708-ff85-4971-aa4f-7742a56d0003",
   "metadata": {},
   "source": [
    "## INSERTING PLAYER NAMES/ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d84565-ae98-40e7-a124-3b627512ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = pd.read_excel(\"Data/names_backup.csv\", sheet_name='names').replace(np.nan, None)#, index_col='playerId').replace(np.nan, None)\n",
    "#updates, adds, delete, Sheet2\n",
    "players = pd.read_excel(\"Data/adds.xlsx\", sheet_name='Sheet1')\n",
    "players = players.replace(np.nan, None).replace(0,None)\n",
    "players.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e72a78-de5d-4897-87b7-aaebb4987d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = mysql.connector.connect(user=dbUser, password=dbPw,\n",
    "                              host=dbHost,database=dbName)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query_insert = \"\"\"\n",
    "        INSERT INTO player \n",
    "            (posId, teamId, name, espnId, espnName, bpId, bpName, nflId, nflName, fpId, fpName, cbsId, cbsName)\n",
    "        VALUES \n",
    "            (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"    \n",
    "    query_update = \"\"\"\n",
    "        REPLACE INTO player \n",
    "            (playerId, posId, teamId, name, espnId, espnName, bpId, bpName, nflId, nflName, fpId, fpName, cbsId, cbsName)\n",
    "        VALUES \n",
    "            (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\" \n",
    "    query_update1 = \"\"\"\n",
    "        UPDATE player \n",
    "        SET \n",
    "            mflId = %s, sportradarId = %s, gsisId = %s, pffId = %s,  sleeperId = %s, yahooId = %s, \n",
    "            fleaflickerId = %s, rotowireId = %s, rotoworldId = %s,  ktcId = %s, pfrId = %s, \n",
    "            cfbrefId = %s, statsId = %s, statsglobalId = %s, fantasydataId = %s, swishId = %s\n",
    "        WHERE playerId = %s\n",
    "    \"\"\"\n",
    "    \n",
    "    query_insert1 = \"\"\"\n",
    "        INSERT INTO player \n",
    "            (posId, teamId, cbsId, cbsName, name)\n",
    "        VALUES \n",
    "            (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    \n",
    "    query_delete = '''\n",
    "        DELETE FROM player\n",
    "        WHERE playerId = %s\n",
    "    '''\n",
    "    \n",
    "    query_update = '''\n",
    "        UPDATE projection SET playerID = %s WHERE playerId = %s\n",
    "    '''\n",
    "    \n",
    "    cursor.executemany(query_update1, players.values.tolist())\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443c280-a91d-4eb2-adde-eb12ea04c7e6",
   "metadata": {},
   "source": [
    "## ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee932b55-72eb-42b3-8f76-b77ee492034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    engine = create_engine(dbConnectionString)\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # columns for db table adp\n",
    "    adp_columns = ['outlet', 'date', 'playerId', 'adp','high','low']\n",
    "\n",
    "    #main df to hold all data\n",
    "    df_load_adp = pd.DataFrame(columns = adp_columns)\n",
    "\n",
    "    directory = r\"..\\data\\adp\"\n",
    "    #looping through every ADP file to aggregate into single df\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory,filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            temp = pd.read_excel(f, parse_dates=['date'])\n",
    "\n",
    "            # creating dicts to convert outlet name/id to db id\n",
    "            if 'cbs' in f:\n",
    "\n",
    "                # creating cbs ID to db ID map\n",
    "                lookup = pd.read_sql(\"SELECT playerId, cbsId FROM player WHERE cbsId IS NOT NULL;\", conn)\n",
    "                lookup = pd.Series(lookup['playerId'].values, index=lookup.cbsId).to_dict()\n",
    "\n",
    "            elif 'espn' in f:\n",
    "                # espn source data does not have playerId for the defenses\n",
    "                # converting full team name to db table 'TEAM'.name\n",
    "                lookup = pd.read_sql(\"SELECT espnId, name FROM player WHERE espnId IS NOT NULL;\", conn)\n",
    "                lookup = pd.Series(lookup.espnId.values, index=lookup.name).to_dict()\n",
    "\n",
    "                # updating the player table team name to player table Id\n",
    "                temp['team'] = temp['team'].str.upper()\n",
    "                temp.loc[temp['playerId'].isna(), 'playerId'] = temp.loc[temp['playerId'].isna(), 'team'].map(lookup)\n",
    "\n",
    "                lookup = pd.read_sql(\"SELECT espnId, playerId FROM player WHERE espnId IS NOT NULL;\", conn)\n",
    "                lookup = pd.Series(lookup.playerId.values, index=lookup.espnId).to_dict()\n",
    "\n",
    "\n",
    "            elif 'fp' in f:\n",
    "\n",
    "                # updating the fantasy pro source data id to db id\n",
    "                temp = temp.loc[pd.notnull(temp['adp'])]\n",
    "\n",
    "                lookup = pd.read_sql(\"SELECT playerId, fpId FROM player WHERE fpId IS NOT NULL;\", conn)\n",
    "                lookup = pd.Series(lookup.playerId.values, index=lookup.fpId).to_dict()\n",
    "\n",
    "\n",
    "\n",
    "            # using the lookup to make the change from outletId to dbId\n",
    "            temp['playerId'] = temp['playerId'].map(lookup)\n",
    "\n",
    "            # updating outlet name to db outlet id \n",
    "            temp['outlet'] = temp['outlet'].replace(outletLookup)\n",
    "\n",
    "\n",
    "            temp = temp[adp_columns]\n",
    "            # adding outlet dataframe to the upload dataframe\n",
    "            df_load_adp = pd.concat([df_load_adp, temp])\n",
    "\n",
    "    df_load_adp = df_load_adp.replace(np.nan, None)\n",
    "    conn.close()\n",
    "    \n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b71b04-c152-4d56-9cbe-9f77b9e9392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #engine = create_engine(dbConnectionString)\n",
    "    #conn = engine.connect()\n",
    "    conn = mysql.connector.connect(user=dbUser, password=dbPw,\n",
    "                              host=dbHost,database=dbName)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query_insert = \"\"\"\n",
    "        INSERT INTO adp \n",
    "\n",
    "        VALUES \n",
    "            (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.executemany(query_insert, df_load_adp.values.tolist())\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "except Exception as ex:\n",
    "    conn.rollback()\n",
    "    conn.close()\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9874e7-a6d4-4ed9-b4cb-7abadddc6ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2969b-601c-4169-9101-784ab9394997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
