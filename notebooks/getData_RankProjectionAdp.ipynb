{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be771a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run date: 2025-09-04 \n",
      "Week: 1 \n",
      "inseason run: True \n",
      "export files: True\n"
     ]
    }
   ],
   "source": [
    "##### importing custom modules from the projects folder\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Add project root to sys.path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "import modules.scrapers as scrapers\n",
    "import modules.helperModule as hf\n",
    "##### --------------\n",
    "from datetime import date\n",
    "\n",
    "# ====================================\n",
    "#                    PARAMS \n",
    "# ====================================\n",
    "league = 'nfl'\n",
    "export = True # export to csv files\n",
    "today = date.today()\n",
    "season = 2025\n",
    "week = 1\n",
    "inseason = True  # False for running proj, and rank scrapes in the offseason\n",
    "#week = int(input(\"What week is it >>>>>> ? \"))\n",
    "print('Run date:',today, \"\\nWeek:\", week, '\\ninseason run:', inseason, '\\nexport files:', export)\n",
    "# ====================================\n",
    "\n",
    "scraper = scrapers.scrapers(\n",
    "    season = season,\n",
    "    week = week,\n",
    "    today = today\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393dfb8",
   "metadata": {},
   "source": [
    "# SCRAPE DATA\n",
    "# ============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4dd0e",
   "metadata": {},
   "source": [
    "### INSEASON - Actual game scores and Game betting lines\n",
    "##### run after the last game of the week before TNF game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a0dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraper.cbs_game_scores(inseason = inseason, export = export)\n",
    "scraper.bp_lines(export = export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2663eb",
   "metadata": {},
   "source": [
    "### INSEASON or OFFSEASON - Projections and Rankings\n",
    "##### offseason - run at any time in the offseason once sites put them up\n",
    "##### inseason - run anytime Tues-Thurs before TNF to get the proj or ranks before cames start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7028f15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in- and off-season\n",
    "scraper.cbs_projections(inseason = inseason, export = export)\n",
    "scraper.espn_projections(inseason = inseason, export = export)\n",
    "scraper.nfl_projections(inseason = inseason, export = export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c14652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:1412: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_espn_ranking = pd.concat([df_espn_ranking, temp_df], axis = 0, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(214, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in- and off-season\n",
    "scraper.ffp_ecr_rankings(inseason = inseason, export = export)\n",
    "scraper.espn_rankings(inseason = inseason, export = export)\n",
    "scraper.nfl_rankings(inseason = inseason, export = export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dab6a5",
   "metadata": {},
   "source": [
    "###  OFFSEASON - ADPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16577e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraper.cbs_adp(export = export)\n",
    "#scraper.ffp_adp(export = export)\n",
    "#scraper.espn_adp(export = export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502c7f8",
   "metadata": {},
   "source": [
    "### OFFSEASON - player full season yard and td props "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffe10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rushing_yds 1 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 2 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 3 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 4 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 5 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 6 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 7 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 8 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 9 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 10 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 11 <Response [200]>\n",
      "made soup\n",
      "total_rushing_yds 12 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 1 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 2 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 3 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 4 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 5 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 6 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 7 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 8 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 9 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 10 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 11 <Response [200]>\n",
      "made soup\n",
      "total_rushing_tds 12 <Response [200]>\n",
      "soup ruined\n",
      "total_receiving_yds 1 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 2 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 3 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 4 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 5 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 6 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 7 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 8 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 9 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 10 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 11 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 12 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 13 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 14 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 15 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 16 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 17 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 18 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 19 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 20 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 21 <Response [200]>\n",
      "made soup\n",
      "total_receiving_yds 22 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 1 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 2 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 3 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 4 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 5 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 6 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 7 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 8 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 9 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 10 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 11 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 12 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 13 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 14 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 15 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 16 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 17 <Response [200]>\n",
      "made soup\n",
      "total_receiving_tds 18 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 1 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 2 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 3 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 4 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 5 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 6 <Response [200]>\n",
      "made soup\n",
      "total_passing_yds 7 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 1 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 2 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 3 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 4 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 5 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 6 <Response [200]>\n",
      "made soup\n",
      "total_passing_tds 7 <Response [200]>\n",
      "made soup\n"
     ]
    }
   ],
   "source": [
    "#scraper.bp_season_player_total_props()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025001d",
   "metadata": {},
   "source": [
    "# PROCESS SCRAPED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e95e51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query successful\n",
      "query successful\n",
      "query successful\n",
      "query successful\n",
      "query successful\n",
      "query successful\n"
     ]
    }
   ],
   "source": [
    "# hit db to standardize player, team, outlet, etc... ids \n",
    "scraper.generate_id_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8764072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2763: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_missing_players_proj = pd.concat(\n",
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2776: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_load_proj = pd.concat([df_load_proj, temp])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 missing players..\n",
      "query successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\helperModule.py:323: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_missing_players['joinName'] = df_missing_players['name'].str.lower().apply(apply_regex_replacements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query successful\n",
      "successfully added data to player\n",
      "inserts completed..\n",
      "updates completed...\n"
     ]
    }
   ],
   "source": [
    "scraper.process_projections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be0e48ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2619: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_missing_players_rank = pd.concat([\n",
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\scrapers.py:2641: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_load_rank = pd.concat([df_load_rank, temp])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 missing players..\n",
      "query successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrbrz\\Desktop\\projects\\projects\\fantasyfootball\\modules\\helperModule.py:323: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_missing_players['joinName'] = df_missing_players['name'].str.lower().apply(apply_regex_replacements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query successful\n",
      "successfully added data to player\n",
      "inserts completed..\n",
      "updates completed...\n"
     ]
    }
   ],
   "source": [
    "scraper.process_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b902098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    }
   ],
   "source": [
    "#scraper.scraped_dfs['lines']['bp'] = None\n",
    "scraper.process_game_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b8491",
   "metadata": {},
   "source": [
    "#### OFFSEASON ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraper.process_adps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run when season total props are scraped.\n",
    "#scraper.process_season_player_total_props()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc50fc",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73960d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPROJ:\u001b[39m\u001b[33m'\u001b[39m, scraper.processed_dfs[\u001b[33m'\u001b[39m\u001b[33mprojections\u001b[39m\u001b[33m'\u001b[39m].shape,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRANK:\u001b[39m\u001b[33m'\u001b[39m, scraper.processed_dfs[\u001b[33m'\u001b[39m\u001b[33mrankings\u001b[39m\u001b[33m'\u001b[39m].shape,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mADP:\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocessed_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43madps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'PROJ:', scraper.processed_dfs['projections'].shape,\n",
    "    '\\nRANK:', scraper.processed_dfs['rankings'].shape,\n",
    "    #'\\nADP:', scraper.processed_dfs['adps'].shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "558f8fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4039, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================\n",
    "# remove nan player ids if the loads fail below\n",
    "# COME BACK TO HERE IF THE 3 expor_Database() calls below fail for nans \n",
    "# =============================================\n",
    "table = 'rankings'\n",
    "\n",
    "scraper.processed_dfs[table] = scraper.processed_dfs[table][\n",
    "    scraper.processed_dfs[table]['playerId'].notna()\n",
    "]\n",
    "scraper.processed_dfs[table].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27277712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully added data to projection\n"
     ]
    }
   ],
   "source": [
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['projections'],\n",
    "    database_table='projection', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55a50453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully added data to ranking\n"
     ]
    }
   ],
   "source": [
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['rankings'],\n",
    "    database_table='ranking', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eed70879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully added data to betting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['lines'], \n",
    "    database_table='betting', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d88d6",
   "metadata": {},
   "source": [
    "#### OFFSEASON ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADP \n",
    "\"\"\"\n",
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['adps'],\n",
    "    database_table='adp', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43335fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# season total props\n",
    "\"\"\"\n",
    "hf.export_database(\n",
    "    dataframe=scraper.processed_dfs['seasonprops'], \n",
    "    database_table='odds_season_totals', \n",
    "    connection_string=None, \n",
    "    if_exists='append'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8a69a",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43037f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load sleeper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasyfootball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
